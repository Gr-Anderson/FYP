{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import serial\n",
    "import sqlite3\n",
    "import json\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "from scipy.signal import argrelextrema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BiometricSignal Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 110,  244,  373,  499,  623,  748,  873,  998, 1123]),)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class BiometricSignal: \n",
    "    \"\"\"\n",
    "    A class used to represent an ECG signal\n",
    "\n",
    "    ...\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    captured_signal_csv : str\n",
    "        a string representing a path to a csv file\n",
    "\n",
    "    Methods\n",
    "    -------\n",
    "    capture_signal()\n",
    "        Captures an ECG signal with an Arduino and AD8232\n",
    "    output_signal_to_csv()\n",
    "        Outputs the signal captured to a csv name in 'captured_signal_csv'\n",
    "    filter_captured_signal()\n",
    "        Filters the ECG to reduce noise\n",
    "    amend_signal(filtered_signal)\n",
    "        Removes start and end of signal which are usually very noisy\n",
    "    find_r_peaks(amended_signal)\n",
    "        Finds the R-peaks in the signal\n",
    "    \"\"\"\n",
    "    \n",
    "    captured_signal_csv = \"./assets/subject_raw_ecg.csv\"\n",
    "#     captured_signal_csv = \"./subject2.csv\"\n",
    "#     captured_signal_csv = \"./subject3a.csv\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        captured_ecg : list\n",
    "            List containing the ECG captured by the Arduino and AD8232\n",
    "        filtered_signal : numpy.ndarray\n",
    "            The signal with most of the noise removed\n",
    "        amended_signal : numpy.ndarray\n",
    "            The signal with the start and the end removed\n",
    "        r_peaks : tuple\n",
    "            Contains the positions of the R-peaks in the signal\n",
    "        \"\"\"\n",
    "        \n",
    "        self.captured_ecg = []\n",
    "        self.filtered_signal = np.ndarray([])\n",
    "        self.amended_signal = np.ndarray([])\n",
    "        self.r_peaks = ()\n",
    "        \n",
    "        \n",
    "    def capture_signal(self):\n",
    "        r\"\"\"Captures ECG signal from Arduino and AD8232.\n",
    "\n",
    "        This function captures an ECG signal with an Arduino and AD8232\n",
    "        on the port specified in `serial_data`. Before it begins capturing,\n",
    "        there is a small delay (e.g. 2 seconds) to allow the user to get\n",
    "        comfortable. After this delay it will capture the ECG signal and\n",
    "        assign it to the list `self.captured_ecg`.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        serial_data : serial.serialposix.Serial, optinal\n",
    "            Identifies the port to record the ECG signal, default is\n",
    "            serial.Serial(\"/dev/ttyACM2\", 9600)\n",
    "        capture_time : int, optional\n",
    "            Time in seconds to capture ECG signal for, default is 5 \n",
    "        start_delay : numpy.ndarray\n",
    "            Time in seconds to delay before recording starts, default is 2\n",
    "\n",
    "        \"\"\"\n",
    "        \n",
    "        t_end = time.time() + capture_time\n",
    "        time.sleep(start_delay)\n",
    "\n",
    "        while time.time() < t_end:\n",
    "            while serial_data.inWaiting() == 0:\n",
    "                pass\n",
    "            temp_string = serial_data.readline()\n",
    "            serial_string = (\n",
    "                str(temp_string)\n",
    "                .replace(\"b\", \"\")\n",
    "                .replace(\"'\", \"\")\n",
    "                .replace(\"\\\\r\", \"\")\n",
    "                .replace(\"\\\\n\", \"\")\n",
    "            )\n",
    "            if len(serial_string) == 3:\n",
    "                self.captured_ecg.append(int(serial_string))\n",
    "#         return self.captured_ecg\n",
    "\n",
    "\n",
    "    def output_signal_to_csv(self):\n",
    "        \n",
    "        r\"\"\"Coverts `self.captured_ecg` to a csv\n",
    "\n",
    "        This function converts the list `self.captured_ecg` to a csv and\n",
    "        saves it to the location set in `captured_signal_csv`.\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        with open(BiometricSignal.captured_signal_csv, \"w\") as ecg_file:\n",
    "            ecg_file.write(\"voltage,\\n\")\n",
    "            for item in self.captured_ecg:\n",
    "                ecg_file.write(\"%s,\\n\" % item)\n",
    "            ecg_file.write(\"0,\")\n",
    "\n",
    "\n",
    "    def filter_captured_signal(self):\n",
    "        \n",
    "        r\"\"\"Reduces noise in the signal.\n",
    "\n",
    "        Reduces noise which in picked up when recording an ECG signal.\n",
    "        It uses a Butterworth filter to remove jagged parts of the signal\n",
    "        and smoothen it give a more truer represtation of the ECG signal.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        self.filtered_signal : numpy.ndarray\n",
    "            A filtered version of the captured ECG signal \n",
    "\n",
    "        \"\"\"\n",
    "            \n",
    "        numerator, denominator = signal.butter(4, 0.25, analog=False)\n",
    "        data = pd.read_csv(BiometricSignal.captured_signal_csv)\n",
    "        sig = data[\"voltage\"]\n",
    "        self.filtered_signal = signal.filtfilt(numerator, denominator, sig)\n",
    "        return self.filtered_signal\n",
    "    \n",
    "    def amend_signal(self, start = 100, end = -100):\n",
    "        r\"\"\"Removes the begining and end of a filtered signal\n",
    "\n",
    "        Sometimes there can be a lot of noise at the start and of a ECG\n",
    "        signal which the `filter_captured_signal` function is unable to remove.\n",
    "        The noise is caused by connecting to and from the capture device. This\n",
    "        function takes care of that of that noise by removing the start and end of\n",
    "        the captured ECG signal.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        start : int, optinal\n",
    "            The position to start the clip the ECG signal from, default is 100\n",
    "        end : int, optional\n",
    "            The position to end the clip of the ECG signal, default is 100\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        self.amended_signal : numpy.ndarray\n",
    "            An ammended version of `filtered_signal` \n",
    "            \n",
    "        \"\"\"\n",
    "             \n",
    "        self.amended_signal = self.filtered_signal[start:end]\n",
    "        return self.amended_signal\n",
    "    \n",
    "    def find_r_peaks(self, threshold = 400):\n",
    "        r\"\"\"Finds the R-peaks in an amended signal\n",
    "\n",
    "        This function finds the R-peaks in an amended signal. R-peaks are \n",
    "        the highest part of a signal so it uses a threshold to illimitate lower\n",
    "        unnesscary features which may be picked up as a false positive. \n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        threshold : int, optinal\n",
    "            The position to start looking for R-peaks from, default is 400\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        self.r_peaks : tuple\n",
    "            A tuple containing the positions of the R-peaks \n",
    "            \n",
    "        \"\"\"\n",
    "        \n",
    "        no_of_rows = self.amended_signal.shape[0]\n",
    "        line_numbers = []\n",
    "        theVoltage = []\n",
    "\n",
    "\n",
    "        for i in range(0, no_of_rows):\n",
    "            if self.amended_signal[i] > threshold:\n",
    "                theVoltage.append(self.amended_signal[i])\n",
    "            else:\n",
    "                theVoltage.append(0)\n",
    "            line_numbers.append(i)    \n",
    "\n",
    "\n",
    "        ecg_plot = np.concatenate((theVoltage, line_numbers))\n",
    "\n",
    "        self.r_peaks = argrelextrema(ecg_plot, np.greater, order=5)\n",
    "        \n",
    "        return self.r_peaks\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------------------------------\n",
    "#                                       CODE FOR TESTING\n",
    "# ----------------------------------------------------------------------------------------------\n",
    "biosig = BiometricSignal()\n",
    "biosig.filter_captured_signal()\n",
    "biosig.amend_signal()\n",
    "biosig.find_r_peaks()\n",
    "# print(biosig.filter_captured_signal)\n",
    "# TEST_filtered_signal = TEST_signal.filter_captured_signal()\n",
    "# TEST_amended_signal = TEST_signal.amend_signal()\n",
    "# TEST_r_peaks = TEST_signal.find_r_peaks()\n",
    "# testytesttest = np.ndarray([])\n",
    "# serial_data = serial.Serial(\"/dev/ttyACM2\", 9600)\n",
    "# print(type(TEST_r_peaks))\n",
    "# help(BiometricSignal)\n",
    "# plt.figure(num=None, figsize=(10, 5), dpi=80, facecolor=\"w\", edgecolor=\"k\")\n",
    "# plt.plot(TEST_amended_signal, color=\"#000000\", linewidth=1)\n",
    "# plt.axis('off')\n",
    "# plt.savefig(\"project_presentation.png\", dpi=150, quality=100, bbox_inches='tight')\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Segment Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2548.97502232, 2458.50363072, 2188.71486457, 1833.36450487,\n",
       "       1513.84803125, 1321.31750675, 1280.24088199, 1351.16072336,\n",
       "       1464.07686936, 1557.73497385, 1602.98761294, 1603.46827222,\n",
       "       1581.00305249, 1558.37530351, 1548.63905135, 1553.36720097,\n",
       "       1566.95026276, 1582.36964276, 1595.10454458, 1604.14778807,\n",
       "       1610.91113603, 1617.45704888, 1625.19842692, 1634.49869171,\n",
       "       1644.97716774, 1656.05755783, 1667.38446742, 1678.96289291,\n",
       "       1691.05219628, 1703.92702926, 1717.64269042, 1731.92263723,\n",
       "       1746.21370678, 1759.85901633, 1772.27503956, 1783.0278814 ,\n",
       "       1791.78877457, 1798.25649021, 1802.1610223 , 1803.36494664,\n",
       "       1801.95726796, 1798.22496327, 1792.49163213, 1784.91852134,\n",
       "       1775.39447319, 1763.60224264, 1749.25551581, 1732.37918865,\n",
       "       1713.4448657 , 1693.26463566, 1672.73245751, 1652.60424507,\n",
       "       1633.43551962, 1615.64925195, 1599.62879227, 1585.7533044 ,\n",
       "       1574.36006538, 1565.66934825, 1559.71239899, 1556.28300223,\n",
       "       1554.93983772, 1555.10309438, 1556.23827564, 1558.0226197 ,\n",
       "       1560.37197057, 1563.3121702 , 1566.80059871, 1570.6266976 ,\n",
       "       1574.44397059, 1577.8887757 , 1580.6998931 , 1582.78528437,\n",
       "       1584.23415414, 1585.28136989, 1586.21655608, 1587.25599607,\n",
       "       1588.44761187, 1589.67510205, 1590.75411338, 1591.55081163,\n",
       "       1592.05269967, 1592.35797952, 1592.59380248, 1592.81961621,\n",
       "       1592.99025932, 1593.01162016, 1592.85770244, 1592.69804334,\n",
       "       1592.99222632, 1594.48801583, 1598.04716993, 1604.30195585,\n",
       "       1613.28318048, 1624.21797974, 1635.6158416 , 1645.63343397,\n",
       "       1652.61774749, 1655.6583795 , 1654.9220164 , 1651.57295488,\n",
       "       1647.26502805, 1643.43138728, 1640.70945937, 1638.73694022,\n",
       "       1636.35744677, 1632.13365759, 1624.98944456, 1614.74053724,\n",
       "       1602.29208567, 1589.46168122, 1578.58458754, 1572.01931555,\n",
       "       1571.44388729, 1576.82263974, 1585.37546929, 1591.46508087,\n",
       "       1588.39388557, 1572.31394508, 1546.99053996, 1526.68364471,\n",
       "       1533.95068186, 1590.79360459, 1705.43581149, 1861.37916902])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Segment:\n",
    "    \"\"\"\n",
    "    A segment is a section of an ECG signal between two neighbouring R-peaks\n",
    "\n",
    "    ...\n",
    "    \n",
    "    Attributes\n",
    "    ----------\n",
    "    no_of_segments : int\n",
    "        a int representing the number of segemnts to overlay\n",
    "        \n",
    "    Methods\n",
    "    -------\n",
    "    combining_segments()\n",
    "        Combines multiple segments, overlayed on each other\n",
    "    get_mean_of_segments()\n",
    "        Finds the mean of multiple segments\n",
    "    standardise_mean_segment()\n",
    "        Standardises a mean segment for processing\n",
    "    find_features_lower()\n",
    "        Finds the lower unique features of a segment\n",
    "    find_features_higher()\n",
    "        Finds the higher unique features of a segment\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    no_of_segments = 5\n",
    "    \n",
    "    \n",
    "    def __init__(self, bio_signal):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        bio_signal : BiometricSignal\n",
    "            An ECG signal object\n",
    "        combined_seg : numpy.ndarray\n",
    "            Contains multiple segments overlayed on each other \n",
    "        mean_segment : numpy.ndarray\n",
    "            The result of combining multiple segments\n",
    "        standardised_mean_segment : numpy.ndarray\n",
    "            Standareised mean segment, standisatin in nesscessary for processing\n",
    "        features_lower() : tuple\n",
    "            The lower side unique features of a segment\n",
    "        features_higher() : tuple\n",
    "            The higher side unique features of a segment\n",
    "        \"\"\"\n",
    "        \n",
    "        self.bio_signal = bio_signal\n",
    "        self.combined_seg = self.combining_segments()\n",
    "        self.mean_segment = self.get_mean_of_segments()\n",
    "        self.standardised_mean_segment = self.standardise_mean_segment()\n",
    "        self.features_lower = self.find_features_lower()\n",
    "        self.features_higher = self.find_features_higher()\n",
    "\n",
    "\n",
    "    def combining_segments(self):\n",
    "        r\"\"\"Combines multiple segments, overlayed on each other\n",
    "\n",
    "        This function combines multiple neighbouring R-peaks and overlays them\n",
    "        to form a single segment. This is the first step in finding a mean\n",
    "        segment.\n",
    "                   \n",
    "        Returns\n",
    "        -------\n",
    "        combined_seg : numpy.ndarray\n",
    "            A numpy array containing multiple segments overlayed on one another\n",
    "        \"\"\"\n",
    "        \n",
    "        combined_seg_does_not_exist = True\n",
    "        smallest_seg = None\n",
    "        \n",
    "        for i in range (0, self.no_of_segments):\n",
    "            segment_start = self.bio_signal.r_peaks[0][i]\n",
    "            segment_end = self.bio_signal.r_peaks[0][i+1]\n",
    "\n",
    "            extracted_segment = self.bio_signal.amended_signal[segment_start:segment_end]\n",
    "            if smallest_seg == None:\n",
    "                smallest_seg = len(extracted_segment)\n",
    "            elif (len(extracted_segment) < smallest_seg):\n",
    "                smallest_seg = len(extracted_segment)\n",
    "\n",
    "            if combined_seg_does_not_exist:\n",
    "                # adds additional zeros to the end of the first segment\n",
    "                # this is to prevent a crash as segments may have differnet lengths\n",
    "                combined_seg = np.zeros(len(extracted_segment) + 100)\n",
    "                combined_seg_does_not_exist = False\n",
    "            for j in range(0,len(extracted_segment)):\n",
    "                combined_seg[j] =  combined_seg[j] + extracted_segment[j]\n",
    "            \n",
    "        combined_seg = np.trim_zeros(combined_seg)\n",
    "        combined_seg = combined_seg[0:smallest_seg]\n",
    "        return combined_seg\n",
    "                \n",
    "\n",
    "    def get_mean_of_segments(self):\n",
    "        r\"\"\"Finds the mean of multiple segments\n",
    "\n",
    "        This function finds the mean segment by looping through each element in\n",
    "        the combined segment and dividing it by `no_of_segments`\n",
    "\n",
    "        mean_segment : numpy.ndarray\n",
    "            A numpy array containing the mean segment of the combined segments\n",
    "        \"\"\"\n",
    "        \n",
    "        mean_segment = np.array([])\n",
    "        \n",
    "        for k in range (0, len(self.combined_seg)):\n",
    "            mean_segment = np.append (mean_segment, self.combined_seg[k] / self.no_of_segments)\n",
    "            \n",
    "        return mean_segment\n",
    "\n",
    "    \n",
    "    def standardise_mean_segment(self):\n",
    "        r\"\"\"Standardises a mean segment for processing\n",
    "\n",
    "        This function is required because not all ECG signals don't start at zero. The\n",
    "        lowest value is found and this is subtracted from every element in the\n",
    "        mean segment.\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        standardised_mean_segment : numpy.ndarray\n",
    "            Standareised mean segment, standisatin in nesscessary for processing\n",
    "        \"\"\"        \n",
    "        \n",
    "        standardised_mean_segment = np.array([])\n",
    "        \n",
    "        min_of_mean_segment = min(self.mean_segment)\n",
    "        for value in range(0, len(self.mean_segment)):\n",
    "            standardised_mean_segment = np.append (standardised_mean_segment, self.mean_segment[value] - min_of_mean_segment)\n",
    "\n",
    "        return standardised_mean_segment\n",
    "    \n",
    "    def find_features_lower(self):\n",
    "        r\"\"\"Finds the lower unique features of a segment\n",
    "\n",
    "        This function uses argrelextrema, part of SciPy. Argrelextrema\n",
    "        calculates the relative extrema of data, this means it examines\n",
    "        data at either side of a point on the segment to identify variation.\n",
    "        When if finds broad variations between points, it considers it unique, \n",
    "        labels that point as a feature and stores it in a tuple.\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        features_lower : tuple\n",
    "            A tuple containing the positions of lower unique features. \n",
    "        \"\"\"\n",
    "        \n",
    "        features_lower = argrelextrema(self.mean_segment, np.less, order=5)\n",
    "        self.features_lower = (features_lower[0],self.mean_segment[features_lower[0]])       \n",
    "        return self.features_lower\n",
    "\n",
    "\n",
    "    def find_features_higher(self):\n",
    "        r\"\"\"Finds the higher unique features of a segment\n",
    "\n",
    "        This function uses argrelextrema, part of SciPy. Argrelextrema\n",
    "        calculates the relative extrema of data, this means it examines\n",
    "        data at either side of a point on the segment to identify variation.\n",
    "        When if finds broad variations between points, it considers it unique, \n",
    "        labels that point as a feature and stores it in a tuple.\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        features_higher : tuple\n",
    "            A tuple containing the positions of higher unique features. \n",
    "        \"\"\"\n",
    "        \n",
    "        features_higher = argrelextrema(self.mean_segment, np.greater, order=5)\n",
    "        self.features_higher = (features_higher[0],self.mean_segment[features_higher[0]]) \n",
    "        return self.features_higher\n",
    "\n",
    "        \n",
    "# ----------------------------------------------------------------------------------------------\n",
    "#                                       CODE FOR TESTING\n",
    "# ----------------------------------------------------------------------------------------------\n",
    "seg = Segment(biosig)\n",
    "seg.combining_segments()\n",
    "seg.\n",
    "seg.\n",
    "seg.\n",
    "# print(type(TEST_segment.features_lower))\n",
    "# print(TEST_segment.combined_seg)\n",
    "# TEST_combined_seg = TEST_segment.combining_segments()\n",
    "# TEST_mean_segment = TEST_segment.get_mean_of_segments(TEST_combined_seg)\n",
    "# TEST_standardised_mean_segment = TEST_segment.standardise_mean_segment(TEST_mean_segment)\n",
    "\n",
    "# END OF SEGMENT CLASS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Templates Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "class Templates:\n",
    "    \"\"\"\n",
    "    A class for templates for ECG signals\n",
    "\n",
    "    ...\n",
    "\n",
    "    Methods\n",
    "    -------\n",
    "    create_table()\n",
    "        Creates the templates table in the database if it doesn't already exist\n",
    "    add_entry_to_database(features_lower, features_higher, standardised_mean_segment, x_length, y_length)\n",
    "        Adds a record to the database\n",
    "    convert_features_to_percentages(features, length)\n",
    "        Converts the feature locations to percentages\n",
    "    query_db(theName)\n",
    "        Searchs for a name in the database\n",
    "    does_user_exist(theName)\n",
    "        Checks to see if user already exists in the database\n",
    "    get_template()\n",
    "        Retrieves a template from the database\n",
    "    template_matching()\n",
    "        Compares the template in the database with a captured one\n",
    "    get_start_end_locations(self, feature_x, feature_y, image_width, image_height)\n",
    "        Uses a feature to determine a area to check for a match\n",
    "    get_feature_location(self, x, y, image_width, image_height)\n",
    "        ddddd\n",
    "    get_feature_from_template(self, db_template_ecg, x_start, x_end, y_start, y_end)\n",
    "        sssssss\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, name):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        name : str\n",
    "            The name of the user\n",
    "        conn : sqlite3.Connection\n",
    "            Connection to the SQLite3 database\n",
    "        c : sqlite3.Cursor\n",
    "            Connection for the SQLite3 database\n",
    "        standardised_mean_segment : numpy.ndarray\n",
    "            Standareised mean segment, standisatin in nesscessary for processing\n",
    "        featuresX : list\n",
    "            A list of all the features on the X axis\n",
    "        featuresY : list\n",
    "            A list of all the features on the Y axis\n",
    "        \"\"\"\n",
    "\n",
    "        self.name = name\n",
    "        self.conn = sqlite3.connect('templatesDB.db')\n",
    "        self.c = self.conn.cursor()\n",
    "        self.create_table()\n",
    "        self.standardised_mean_segment = []\n",
    "        self.featuresX = []\n",
    "        self.featuresY = []\n",
    "    \n",
    "    def create_table(self):\n",
    "        r\"\"\"Creates the templates table in the database if it doesn't already exist\n",
    "\n",
    "        Checks to see if table for the templates exists and creates it if it doesn't.\n",
    "        The table contains the name, mean_segment, features along the X axis and \n",
    "        features along the Y axis\n",
    "        \"\"\"\n",
    "        self.c.execute(\"\"\"CREATE TABLE IF NOT EXISTS templates \n",
    "                                            ( name text,\n",
    "                                                mean_segment text,\n",
    "                                                featuresX text,\n",
    "                                                featuresY text)\"\"\")\n",
    "        self.conn.commit()\n",
    "    \n",
    "    \n",
    "    def add_entry_to_database(self, features_lower, features_higher, standardised_mean_segment,\n",
    "                          x_length, y_length):\n",
    "        r\"\"\"Adds a record to the database\n",
    "\n",
    "        Adds a new user to the database. It starts by converting the feature locations\n",
    "        to percentages for both the lower and higher features. This standardises the \n",
    "        locations making matching more accurate. It then adds them to the database,\n",
    "        combining X axises of both lower and higher features, and doing the\n",
    "        same for the Y axises. It also sotres the user and the user's standarised\n",
    "        mean segment.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        features_lower : tuple\n",
    "            A tuple containing the positions of lower unique features.\n",
    "        features_higher : tuple\n",
    "            A tuple containing the positions of higher unique features.\n",
    "        standardised_mean_segment : numpy.ndarray\n",
    "            Standareised mean segment, standisatin in nesscessary for processing\n",
    "        x_length : int\n",
    "            The length of the X axis\n",
    "        y_length : int\n",
    "            The length of the Y axis \n",
    "        \"\"\"\n",
    "        if self.does_user_exist(self.name) != True:\n",
    "            thefeaturesLowerX = self.convert_features_to_percentages(features_lower[0].tolist(), x_length)\n",
    "            thefeaturesLowerY = self.convert_features_to_percentages(features_lower[1].tolist(), y_length)\n",
    "            thefeaturesHigherX = self.convert_features_to_percentages(features_higher[0].tolist(), x_length)\n",
    "            thefeaturesHigherY = self.convert_features_to_percentages(features_higher[1].tolist(), y_length)\n",
    "\n",
    "            self.c.execute(\"INSERT INTO templates VALUES (:name, :mean_segment, :featuresX, :featuresY)\",\n",
    "                                                {'name': self.name,\n",
    "                                                 'mean_segment': json.dumps(standardised_mean_segment.tolist()),\n",
    "                                                 'featuresX': json.dumps(thefeaturesLowerX + thefeaturesHigherX),\n",
    "                                                 'featuresY': json.dumps(thefeaturesLowerY + thefeaturesHigherY)})\n",
    "\n",
    "\n",
    "            self.conn.commit()\n",
    "        \n",
    "        \n",
    "    def convert_features_to_percentages(self, features, length):\n",
    "        r\"\"\"Converts a feature's location to a percentage\n",
    "\n",
    "        Converts the location of a feature to a percentage for\n",
    "        standardisaion. Standardisation helps with template matching.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        features : numpy.ndarray\n",
    "            description\n",
    "        length : int\n",
    "            The length of the features\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        the_row : list\n",
    "            Returns a list of ints\n",
    "            \n",
    "        \"\"\"\n",
    "        \n",
    "        the_row = []\n",
    "\n",
    "        for value in features:\n",
    "            pos_percentage = (value * 100) // length\n",
    "            the_row.append(pos_percentage)\n",
    "            \n",
    "        return the_row\n",
    "    \n",
    "\n",
    "    def query_db(self, theName):\n",
    "        r\"\"\"Queries the database with the name provided in arguments\n",
    "\n",
    "        Queries the database with the name provided in arguments and\n",
    "        returns the result if there is one.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        theName : str\n",
    "            The name used in the query\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        query_response : tuple\n",
    "            The result, if any, of the query\n",
    "            \n",
    "        \"\"\"\n",
    "        \n",
    "        self.c.execute(\"SELECT * FROM templates WHERE name IS (:name)\", {'name': theName})\n",
    "        query_response=(self.c.fetchone())        \n",
    "        return query_response\n",
    "    \n",
    "    def does_user_exist(self, theName):\n",
    "        r\"\"\"Queries the database with the name provided in arguments\n",
    "\n",
    "        Queries the database with the name provided in arguments and\n",
    "        returns a bool.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        theName : str\n",
    "            The name used in the query\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        bool\n",
    "            True or false, depending on if name is found in database\n",
    "        \"\"\"\n",
    "        \n",
    "        if self.query_db(theName) == []:\n",
    "            return False\n",
    "        else:\n",
    "            return True\n",
    "        \n",
    "        \n",
    "    def get_template(self, theName):\n",
    "        r\"\"\"Retrieves template from the database\n",
    "\n",
    "        Queries the database with the name provided in arguments and\n",
    "        returns the result if there is one.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        theName : str\n",
    "            The name used in the query\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        standardised_mean_segment : list\n",
    "            The users segment\n",
    "        featuresX : list\n",
    "            The X cordinates of the the features\n",
    "        featuresY : list\n",
    "            The X cordinates of the the features            \n",
    "        \"\"\"\n",
    "        \n",
    "        if self.does_user_exist(theName):\n",
    "            query_response = self.query_db(theName)\n",
    "            self.standardised_mean_segment = json.loads(query_response[1])\n",
    "            self.featuresX = json.loads(query_response[2])\n",
    "            self.featuresY = json.loads(query_response[3])\n",
    "            return self.standardised_mean_segment, self.featuresX, self.featuresY\n",
    "    \n",
    "    \n",
    "    def template_matching(self):\n",
    "        r\"\"\"Compares the captured template with the one in the database\n",
    "\n",
    "        Compares the captured template with the one in the database. Loops\n",
    "        through each each feature of the captured ECG signal and compares\n",
    "        it to that in the database.\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        success_rate : float\n",
    "            The success rate of the matches\n",
    "        \"\"\"\n",
    "        \n",
    "        self.featuresY =  [int(i) for i in featuresY]\n",
    "     \n",
    "        db_template_ecg = cv2.imread(\"./assets/db_template.png\", 0)\n",
    "        captured_ecg = cv2.imread(\"./assets/TEST_standardised_mean_segment.png\", 0)\n",
    "\n",
    "        \n",
    "        total_matches = 0\n",
    "        successful_matches = 0\n",
    "        \n",
    "        for x,y in zip(self.featuresX, self.featuresY):\n",
    "            \n",
    "            if x > 10 and x < 90 and y > 10 and y < 90 :\n",
    "\n",
    "                image_width, image_height = db_template_ecg.shape        \n",
    "                feature_x, feature_y = self.get_feature_location(x, y, image_width, image_height)\n",
    "                x_start, x_end, y_start, y_end = self.get_start_end_locations(feature_x, feature_y, image_width, image_height)\n",
    "\n",
    "                feature_to_match = self.get_feature_from_template(db_template_ecg, x_start, x_end, y_start, y_end)\n",
    "\n",
    "                w, h = feature_to_match.shape[::-1]\n",
    "                res = cv2.matchTemplate(captured_ecg,feature_to_match,cv2.TM_CCOEFF_NORMED)\n",
    "\n",
    "                threshold = 0.9      \n",
    "                loc = np.where( res >= threshold)\n",
    "                if np.amax(res) > threshold:\n",
    "                    total_matches += 1\n",
    "                    successful_matches += 1\n",
    "                else:\n",
    "                    total_matches += 1\n",
    "\n",
    "        success_rate = (successful_matches * 100) / total_matches\n",
    "        return success_rate\n",
    "    \n",
    "\n",
    "    \n",
    "    def get_start_end_locations(self, feature_x, feature_y, image_width, image_height):\n",
    "        r\"\"\"Identifies area to check on the template\n",
    "\n",
    "        The features are a single point on the segment, this function\n",
    "        takes the area around that point to include in the template match\n",
    "        to increase its accuracity. It also takes into account where\n",
    "        the point is, and if its close to an edge to make sure it doesn't\n",
    "        go out of bounds.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        feature_x : list\n",
    "            The cordinates on X axis\n",
    "        feature_y : list\n",
    "            The cordinates on Y axis\n",
    "        image_width : int\n",
    "            The segments width\n",
    "        image_height : int\n",
    "            The segments length\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        x_start : int\n",
    "            The starting X cordinate needed for OpenCV\n",
    "        x_end : int\n",
    "            The ending X cordinate needed for OpenCV\n",
    "        y_start : int\n",
    "            The starting Y cordinate needed for OpenCV\n",
    "        y_end : type\n",
    "            The ending Y cordinate needed for OpenCV  \n",
    "        \"\"\"\n",
    "        \n",
    "        margin = 10\n",
    "        \n",
    "        if feature_x < margin:\n",
    "            x_start = feature_x\n",
    "        else:\n",
    "            x_start = feature_x - margin\n",
    "\n",
    "        if feature_x > image_width:\n",
    "            x_end = image_width\n",
    "        else:\n",
    "            x_end = feature_x + margin  \n",
    "\n",
    "        if feature_y < margin:\n",
    "            y_start = 0\n",
    "        else:\n",
    "            y_start = feature_y - margin\n",
    "\n",
    "        if feature_y > image_height:\n",
    "            y_end = image_height\n",
    "        else:\n",
    "            y_end = feature_y + margin\n",
    "            \n",
    "        return x_start, x_end, y_start, y_end\n",
    "            \n",
    "            \n",
    "    def get_feature_location(self, x, y, image_width, image_height):\n",
    "        r\"\"\"Converts a feature location to a percentage\n",
    "\n",
    "        Converts a feature location to a percentage for standardisaion.\n",
    "        Standardisation makes template matching more accurate.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        x : int\n",
    "            description\n",
    "        y : int\n",
    "            description\n",
    "        image_width : int\n",
    "            description\n",
    "        image_height : int\n",
    "            description\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        feature_x : int\n",
    "            description\n",
    "        feature_y : int\n",
    "            description\n",
    "        \"\"\"\n",
    "        \n",
    "        feature_x = (image_width // 100) * x\n",
    "        feature_y = (image_height // 100) * y\n",
    "        return feature_x, feature_y\n",
    "    \n",
    "    def get_feature_from_template(self, db_template_ecg, x_start, x_end, y_start, y_end):\n",
    "        r\"\"\"Gets feature from template to check\n",
    "\n",
    "        Converts a feature location to a percentage for standardisaion.\n",
    "        Standardisation makes template matching more accurate.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        name : type\n",
    "            description\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        name : type\n",
    "            description\n",
    "            \n",
    "        \"\"\"\n",
    "        \n",
    "        feature_to_match = db_template_ecg[x_start:y_start,x_end:y_end]\n",
    "        return feature_to_match\n",
    "    \n",
    "    \n",
    "#     def show_image(self, captured_ecg):\n",
    "#         cv2.imshow('Detected',captured_ecg)\n",
    "#         cv2.waitKey(0) & 0xFF\n",
    "#         cv2.destroyAllWindows()\n",
    "    \n",
    "TEST_templates = Templates('Sam')\n",
    "TEST_the_name = 'Sam'\n",
    "TEST_templates.add_entry_to_database(TEST_segment.features_lower, TEST_segment.features_higher,\n",
    "                                     TEST_segment.standardised_mean_segment, len(TEST_segment.combined_seg), \n",
    "                                     len(TEST_segment.standardised_mean_segment))\n",
    "TEST_query_response = TEST_templates.query_db('Sam')\n",
    "TestyMacTestFace = json.loads(TEST_query_response[1])\n",
    "\n",
    "# print(TEST_query_response[1])\n",
    "# print(TEST_templates.name)\n",
    "# print(TEST_templates.featuresX)\n",
    "# print(TEST_templates.featuresY)\n",
    "# TEST_templates.get_template()\n",
    "# print(type(TEST_query_response))\n",
    "# print(TEST_templates.featuresY)\n",
    "TEST_standardised_mean_segment, TEST_featuresX, TEST_featuresY = TEST_templates.get_template(TEST_the_name)\n",
    "# print(TEST_standardised_mean_segment)\n",
    "print(type(TEST_featuresX))\n",
    "# TEST_templates.get_template()\n",
    "# TEST_templates.template_matching(TEST_featuresLowerX, TEST_featuresLowerY, TEST_featuresHigherX, TEST_featuresHigherY)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.8 64-bit ('biometric_authentication': virtualenv)",
   "language": "python",
   "name": "python36864bitbiometricauthenticationvirtualenv54dcfa07294e40f484703143c5416b0f"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
